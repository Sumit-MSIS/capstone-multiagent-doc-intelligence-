

# ğŸš€ MLflow Tracing Application â€“ README

## ğŸ“Œ Overview

This repository hosts a **multi-branch, multi-service architecture** consisting of:

1. **Streamlit Frontend (Main Branch)**
   A lightweight UI allowing users to interact with the chatbot application.

2. **Backend API (Backend Branch)**
   A FastAPI-based microservice that powers the chatbot logic and connects with MLflow for experiment tracking.

3. **MLflow Tracking Server (MLflow Branch)**
   A fully containerized MLflow server with MySQL backend and S3 artifact storage used for tracing model runs, experiments, logs, and metrics.

The application is designed to provide **end-to-end observability**, allowing users to track every inference, input payload, and associated metadata through MLflow while interacting via Streamlit.

---

# ğŸ—ï¸ Architecture Diagram

```
                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                       â”‚      Streamlit UI       â”‚
                       â”‚   (Main Branch Docker)  â”‚
                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                     â”‚ API Calls
                                     â–¼
                     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                     â”‚          FastAPI Backend        â”‚
                     â”‚      (Backend Branch Docker)    â”‚
                     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                         â”‚ MLflow Logging
                                         â–¼
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚         MLflow Tracking Server       â”‚
                      â”‚       (MLflow Branch Docker)         â”‚
                      â”‚  MySQL Backend + S3 Artifact Store   â”‚
                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

# ğŸŒ Hosted URLs

| Service                    | URL                                                                  |
| -------------------------- | -------------------------------------------------------------------- |
| **Streamlit App**          | [http://52.70.125.119:8501/](http://52.70.125.119:8501/)             |
| **FastAPI Backend**        | [http://52.70.125.119:9000/docs#/](http://52.70.125.119:9000/docs#/) |
| **MLflow Tracking Server** | [http://52.70.125.119:8000/](http://52.70.125.119:8000/)             |

---

# ğŸ“ Repository Structure

This repository has **multiple branches**, each dedicated to a system component:

```
.
â”œâ”€â”€ main                          # Streamlit App (Production UI)
â”‚   â”œâ”€â”€ app.py
â”‚   â”œâ”€â”€ pages/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ README.md
â”‚   â””â”€â”€ requirements.txt
â”‚
â”œâ”€â”€ backend                       # FastAPI Backend
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ routers/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â””â”€â”€ README.md
â”‚
â””â”€â”€ mlflow                        # MLflow Tracking Server
    â”œâ”€â”€ Dockerfile
    â”œâ”€â”€ start.sh
    â”œâ”€â”€ requirements.txt
    â”œâ”€â”€ env/.env
    â””â”€â”€ README.md
```

### **How Branches Connect**

* **Streamlit â†’ Backend**: REST API calls to FastAPI deployed on port `9000`.
* **Backend â†’ MLflow**: Uses MLflow Python API to log metrics, params, and outputs.
* **MLflow Server**: Backed by

  * **MySQL** DB (tracking metadata)
  * **S3 bucket** (storing model artifacts)

---

# ğŸ”§ MLflow Tracking Server (This Branch)

## ğŸ“Œ Description

This MLflow deployment uses:

* **MySQL backend store** for experiments & run metadata
* **S3 bucket** for artifacts
* **Dockerized MLflow server** running on port **8000**

It enables:

* Full experiment tracking
* Model versioning
* Parameter + metrics logging
* Input/output traceability

---

# ğŸ“¦ Folder Structure (MLflow Branch)

```
mlflow/
â”œâ”€â”€ Dockerfile              # Builds MLflow server image
â”œâ”€â”€ start.sh                # Entry script to run MLflow server
â”œâ”€â”€ requirements.txt        # Python dependencies
â””â”€â”€ README.md               # This documentation
```

---

# ğŸ“œ File Breakdown

### **requirements.txt**

(Loaded from your uploaded file)

Contains essential packages:

* `mlflow==3.1.4`
* `pymysql`
* `boto3`
* `gunicorn`
* `python-dotenv`

### **start.sh**

```bash
mlflow server \
  --backend-store-uri "mysql+pymysql://admin:Intel%4021@52.70.125.119:3306/mlflow_db_latest" \
  --artifacts-destination "s3://intel-mlflow" \
  --default-artifact-root "s3://intel-mlflow" \
  --host 0.0.0.0 \
  --port 8000
```

Ensures MLflow uses:

* **MySQL** at `52.70.125.119`
* **S3 bucket:** `intel-mlflow`
* **MLflow UI:** port `8000`

---

# ğŸ³ How to Run MLflow via Docker

### 1ï¸âƒ£ Build the Docker Image

```sh
sudo docker stop mlflow-server 
sudo docker rm mlflow-server 
sudo docker build -t mlflow-server . 
```

### 2ï¸âƒ£ Run the Container

```sh
sudo docker run -d
--restart=always
-p 8000:8000
-e AWS_ACCESS_KEY_ID=AKIA2PX4YZCUGBPNG
-e AWS_SECRET_ACCESS_KEY=RW4XRuoOi2Q5S4/j8yMMUBBoAPj6q0pj//U1
-e AWS_DEFAULT_REGION=us-east-1
--name mlflow-server
mlflow-server sudo docker logs mlflow-server --tail=100 -f


```

MLflow UI will be accessible at:
ğŸ‘‰ [[http://52.70.125.119:8000](http://52.70.125.119:8000/ )


---

# ğŸ”§ Running MLflow Without Docker (Local Mode)

### Step 1: Install dependencies

```sh
pip install -r requirements.txt
```

### Step 2: Run the MLflow server

```sh
bash start.sh
```

---

# ğŸ”— Integration With Other Branches

### âœ” Streamlit App Logs User Interactions

The UI collects:

* User input
* Model responses
* Execution timestamps

These are forwarded to the backend.

### âœ” Backend Logs Everything to MLflow

FastAPI backend logs:

* Parameters
* Metrics
* Artifacts
* Payload traces

This provides **full traceability for debugging, analytics, and performance evaluation**.

### âœ” MLflow Server Stores & Displays All Traces

Accessible at:
ğŸ‘‰ [http://52.70.125.119:8000/](http://52.70.125.119:8000/)

---

# ğŸ§ª Testing the Workflow End-to-End

1. **Open Streamlit:**
   [http://52.70.125.119:8501/](http://52.70.125.119:8501/)

2. Ask a question â†’ request goes to FastAPI backend.

3. Backend triggers:

   * Inference
   * Logging â†’ MLflow

4. Visit MLflow UI:
   [http://52.70.125.119:8000/](http://52.70.125.119:8000/)
   Check:

   * Run traces
   * Input/output artifacts
   * Metrics
   * Params

---

# ğŸš€ Production Deployment Notes

### âœ” Each branch has its **own Dockerfile**

You must:

* Switch to the respective branch
* Build the Docker container for that branch
* Deploy each container individually on your EC2 machine

### âœ” Recommended Naming Convention for Images

```
mlflow-tracker:latest
fastapi-backend:latest
streamlit-ui:latest
```

### âœ” Recommended Deployment Order

1. MLflow Server
2. Backend
3. Streamlit App

---

# ğŸ“Œ Environment Variables (Optional)

Place these inside `.env`:

```
MLFLOW_S3_ENDPOINT_URL=https://s3.amazonaws.com
AWS_ACCESS_KEY_ID=<your_key>
AWS_SECRET_ACCESS_KEY=<your_secret>
MYSQL_USER=admin
MYSQL_PASSWORD=password
```

---

# ğŸ› ï¸ Troubleshooting

### MLflow UI not loading?

* Ensure MySQL is reachable from container.
* Ensure S3 bucket exists & IAM permissions are correct.

### Backend not logging?

* Check MLflow tracking URI inside backend code:

  ```python
  mlflow.set_tracking_uri("http://52.70.125.119:8000")
  ```

### Streamlit errors?

* Verify API endpoint:

  ```python
  API_URL = "http://52.70.125.119:9000"
  ```

---

# ğŸ¯ Final Notes

This README provides:

* Fully detailed **Pro-Tier documentation**
* Everything needed for your GitHub repository
* Complete explanation of **multi-branch architecture**
* Instructions for **running**, **deploying**, and **scaling**



